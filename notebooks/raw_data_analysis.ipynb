{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "from os import listdir, path\n",
    "from os.path import isfile, join\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "\n",
    "from pyapnea.oscar.oscar_loader import load_session\n",
    "from pyapnea.oscar.oscar_getter import event_data_to_dataframe, get_channel_from_code\n",
    "from pyapnea.oscar.oscar_constants import CHANNELS, ChannelID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init notebook parameters\n",
    "init_notebook_mode(connected=True)\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_cpap1 = '../data/raw/ResMed_23192565579/Events'\n",
    "list_files = [{'label': f, 'value': f, 'fullpath': join(data_path_cpap1, f)} for f in listdir(data_path_cpap1) if isfile(join(data_path_cpap1, f))]\n",
    "data_path_cpap2= '../data/raw/ResMed_23221085377/Events'\n",
    "list_files.extend([{'label': f, 'value': f, 'fullpath': join(data_path_cpap2, f)} for f in listdir(data_path_cpap2) if isfile(join(data_path_cpap2, f))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_data_to_dataframe_all_channel(oscar_session_data):\n",
    "    global_df = pd.DataFrame(columns=['Col1'])\n",
    "    possible_channels = [ChannelID.CPAP_FlowRate.value, ChannelID.CPAP_Obstructive.value, ChannelID.CPAP_Pressure.value]\n",
    "    for channel in oscar_session_data.data.channels:\n",
    "        if channel.code in possible_channels:\n",
    "            y_col_name = [c[5] for c in CHANNELS if c[1].value == channel.code][0]\n",
    "            gain = channel.events[0].gain\n",
    "            if channel.events[0].t8 == 0:\n",
    "                channel.events[0].time = range(0, channel.events[0].evcount * int(channel.events[0].rate),\n",
    "                                               int(channel.events[0].rate))\n",
    "            df = pd.DataFrame(data={'time': channel.events[0].time,\n",
    "                                    y_col_name+'_no_gain': channel.events[0].data})\n",
    "            df[y_col_name] = df[y_col_name+'_no_gain'] * gain\n",
    "\n",
    "            if channel.events[0].second_field:\n",
    "                # not tested because do not have 2nd field in files\n",
    "                df[y_col_name+'2_no_gain'] = channel.events[0].data2\n",
    "                df[y_col_name + '2'] = df[y_col_name+'2_no_gain'] * gain\n",
    "\n",
    "            df['time_absolute'] = df['time'] + channel.events[0].ts1\n",
    "            df['time_absolute'] = pd.to_datetime(df['time_absolute'], unit='ms')\n",
    "            #df.set_index('time_absolute', inplace=True)\n",
    "            df = df.filter(regex='^(?!.*_no_gain)')\n",
    "            if global_df.empty:\n",
    "                global_df = df\n",
    "            else:\n",
    "                #global_df = pd.merge(global_df, df, right_index=True, left_index=True, how='outer')\n",
    "                global_df = pd.merge(global_df, df, on='time_absolute', how='outer',suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)')\n",
    "                #global_df = pd.concat([global_df, df])\n",
    "\n",
    "    global_df['time_absolute'] = global_df['time_absolute'].dt.tz_localize('UTC')\n",
    "    global_df['local_time'] = global_df['time_absolute'].dt.tz_convert('America/Montreal')\n",
    "    global_df.sort_index(inplace=True)\n",
    "    return global_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying one session and the first event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading files\n",
    "# number 2 has obstructive events\n",
    "filename_to_load = '../data/raw/ResMed_23192565579/Events/62202198.001'\n",
    "\n",
    "oscar_session_data = load_session(filename_to_load)\n",
    "df = event_data_to_dataframe_all_channel(oscar_session_data)\n",
    "\n",
    "# TODO handle Leak two value per time\n",
    "#df_Leak = event_data_to_dataframe(oscar_session_data, ChannelID.CPAP_Leak.value)\n",
    "#np.where(df.index.duplicated(keep=False) == True)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize dataframe to seaborn imput format\n",
    "dfc = df[['FlowRate', 'Obstructive', 'Pressure', 'local_time']]\n",
    "dfm = dfc.melt('local_time', var_name='cols', value_name='vals')\n",
    "dfm.sort_values(by=['local_time'], inplace=True, ignore_index=True)\n",
    "dfm_annotation = dfm[(~pd.isnull(dfm['vals']) & (dfm['cols']=='Obstructive'))]\n",
    "display(dfm_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(25,15)})\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(data=dfm[dfm['cols']!='Pressure'],x='local_time', y='vals', hue='cols', palette=['r', 'g'], ax= ax)\n",
    "ax2 = ax.twinx()\n",
    "# warning : should not interpolate between points...\n",
    "sns.lineplot(data=dfm[dfm['cols']=='Pressure'],x='local_time', y='vals', hue='cols', palette=['b'], ax = ax2)\n",
    "for a in dfm_annotation['local_time']:\n",
    "    plt.axvline(x=a, color='r', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_time = dfm_annotation['local_time'].iloc[0]\n",
    "sns.set(rc={'figure.figsize':(25,15)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_ylim(-40, 50)\n",
    "ax.set_xlim(event_time - datetime.timedelta(seconds=30), event_time + datetime.timedelta(seconds=10))\n",
    "sns.lineplot(data=dfm[dfm['cols']!='Pressure'],x='local_time', y='vals', hue='cols', palette=['r', 'g'], ax = ax)\n",
    "ax2 = ax.twinx()\n",
    "# warning : should not interpolate between points...\n",
    "sns.lineplot(data=dfm[dfm['cols']=='Pressure'],x='local_time', y='vals', hue='cols', palette=['b'], ax = ax2)\n",
    "for a in dfm_annotation['local_time']:\n",
    "    plt.axvline(x=a, color='r', linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "- Number of sessions\n",
    "- Lenght of sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "events_channels = [ChannelID.CPAP_ClearAirway.value,\n",
    "                   ChannelID.CPAP_Obstructive.value,\n",
    "                   ChannelID.CPAP_Hypopnea.value,\n",
    "                   ChannelID.CPAP_Apnea.value, # ClearAway or Obstructive, not determined\n",
    "                   ]\n",
    "event_names = [[c[5] for c in CHANNELS if c[1].value == e][0] for e in events_channels]\n",
    "event_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = dict()\n",
    "stats['nb_sessions'] = len(list_files)\n",
    "stats['sessions'] = []\n",
    "\n",
    "\n",
    "\n",
    "df_event_all_sessions = None\n",
    "\n",
    "#loading all files\n",
    "with tqdm(total=len(list_files)) as pbar:\n",
    "    for f in list_files:\n",
    "        oscar_session_data = load_session(f['fullpath'])\n",
    "        # FlowRate\n",
    "        flowrate_chanel = get_channel_from_code(oscar_session_data, ChannelID.CPAP_FlowRate.value)\n",
    "        flowrate_event = flowrate_chanel.events[0]\n",
    "\n",
    "        stat_session = {'filename': f['label'],\n",
    "                        'nb channel': len(oscar_session_data.data.channels),\n",
    "                        'ts1' : flowrate_event.ts1,\n",
    "                        'ts2' : flowrate_event.ts2,\n",
    "                        'starting time' : datetime.datetime.fromtimestamp(flowrate_event.ts1/1000.0),\n",
    "                        'lenght FlowRate (ms)': flowrate_event.ts2 - flowrate_event.ts1,\n",
    "                        'FlowRate present': (ChannelID.CPAP_FlowRate.value in [c.code for c in oscar_session_data.data.channels])}\n",
    "\n",
    "        # Events\n",
    "        stat_session['events'] = []\n",
    "        for e in events_channels:\n",
    "            event_name = [c[5] for c in CHANNELS if c[1].value == e][0]\n",
    "            event_channel_df = event_data_to_dataframe(oscar_session_data, e)\n",
    "            if not event_channel_df.empty:\n",
    "                df_event = event_channel_df[~pd.isnull(event_channel_df[event_name])]\n",
    "                df_event['type']  = event_name\n",
    "                df_event['session'] = f['value']\n",
    "            else:\n",
    "                df_event = pd.DataFrame(data=[[np.NAN, event_name, f['value']]], columns=['time_absolute', 'type', 'session'])\n",
    "            if df_event_all_sessions is None:\n",
    "                df_event_all_sessions = df_event[['time_absolute', 'type', 'session']]\n",
    "            else:\n",
    "                df_event_all_sessions = pd.concat([df_event_all_sessions,  df_event[['time_absolute', 'type', 'session']]])\n",
    "        stats['sessions'].append(stat_session)\n",
    "        pbar.update(1)\n",
    "        oscar_session_data = None\n",
    "\n",
    "\n",
    "# All event per session\n",
    "print(df_event_all_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats for event\n",
    "# number of event per type\n",
    "df_count_per_type = df_event_all_sessions.groupby(['type'])['time_absolute'].count().to_frame(name = 'count').reset_index().sort_values('type')\n",
    "# number of event per type per session\n",
    "df_count_per_type_per_session = df_event_all_sessions.groupby(['session', 'type'])['time_absolute'].count().to_frame(name = 'count').reset_index().sort_values('type')\n",
    "print(df_count_per_type)\n",
    "print(df_count_per_type_per_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_to_hour_min_sec_ms(ms):\n",
    "    sec, ms = divmod(ms, 1000)\n",
    "    min, sec = divmod(sec, 60)\n",
    "    hour, min = divmod(min, 60)\n",
    "    return hour, min, sec, ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "import math\n",
    "# FlowRate\n",
    "length_array = np.array([s['lenght FlowRate (ms)'] for s in stats['sessions']])\n",
    "avg_len = length_array.mean()\n",
    "med_len = np.median(length_array)\n",
    "stddev_len = stat.stdev(length_array.tolist())\n",
    "stats['FlowRate average length (ms)'] = avg_len\n",
    "stats['FlowRate stddev (ms)'] = stddev_len\n",
    "stats['FlowRate median (ms)'] = med_len\n",
    "stats['FlowRate average length (hmsms))'] = ms_to_hour_min_sec_ms(avg_len)\n",
    "stats['FlowRate stddev (hmsms)'] = ms_to_hour_min_sec_ms(stddev_len)\n",
    "stats['FlowRate median (hmsms)'] = ms_to_hour_min_sec_ms(med_len)\n",
    "\n",
    "# Events\n",
    "stats['events'] = {'count': pd.Series(df_count_per_type['count'].values,index=df_count_per_type['type']).to_dict()}\n",
    "stats['events']['average_sess'] = {e: df_count_per_type_per_session[df_count_per_type_per_session['type']==e].mean(numeric_only=True).to_list()[0] for e in event_names}\n",
    "stats['events']['stddev_sess'] = {e: stat.stdev(df_count_per_type_per_session[df_count_per_type_per_session['type']==e]['count']) for e in event_names}\n",
    "stats['events']['median'] = {e: stat.median(df_count_per_type_per_session[df_count_per_type_per_session['type']==e]['count']) for e in event_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(5,5)})\n",
    "sns.boxplot(data=length_array/1000.0/60/60).set(xlabel='Sessions', ylabel='Length (hour)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb event per session (average + stddev)\n",
    "sns.set(rc={'figure.figsize':(5,5)})\n",
    "sns.barplot(data=df_count_per_type_per_session, x='type', y='count', errorbar='sd').set(xlabel='type of event', ylabel='Nb events per session (avg+stdev)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb event per session (average + stderr)\n",
    "sns.set(rc={'figure.figsize':(5,5)})\n",
    "sns.barplot(data=df_count_per_type_per_session, x='type', y='count', errorbar='se').set(xlabel='type of event', ylabel='Nb events per session (avg+stderr)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_count_per_type_per_session, x='type', y='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb event per type\n",
    "sns.set(rc={'figure.figsize':(5,5)})\n",
    "sns.barplot(data=df_count_per_type, x='type', y='count').set(xlabel='type of event', ylabel='Nb events per type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
